{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///webpack/bootstrap c70048379539057bd6e9","webpack:///./packages/full-text-search/src/inverted_index.js","webpack:///./packages/full-text-search/src/full_text_search.js","webpack:///./packages/full-text-search/src/tokenizer.js","webpack:///./packages/full-text-search/src/utils.js","webpack:///./packages/full-text-search/src/index_searcher.js","webpack:///./packages/full-text-search/src/scorer.js","webpack:///./packages/full-text-search/src/queries.ts"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;ACVA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;AAEA;AACA;;;;;;;;;AC7DkB;;AAElB;AACA;AACA;AACA,WAAW,QAAQ;AACnB;AACA;AACA;AACA,aAAa,QAAQ;AACrB,aAAa,QAAQ;AACrB,aAAa,UAAU;AACvB;AACA,eAAe,oHAAgE,KAAK;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,6BAA6B;AAC7B;AACA;AACA,mBAAmB;AACnB,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,wBAAwB;AAC7C;AACA;AACA;AACA;;AAEA;AACA;AACA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,qBAAqB,qBAAqB;AAC1C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,2BAA2B,iBAAiB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,uBAAuB,iBAAiB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,cAAc,OAAO;AACrB;AACA;AACA;AACA;AACA;AACA,uBAAuB,iBAAiB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,cAAc,MAAM;AACpB;AACA;AACA;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA,0BAA0B,oCAAoC;AAC9D;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,eAAe,MAAM;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,0BAA0B,6BAA6B;AACvD;;AAEA;AACA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAc,mCAAmC;AACjD,aAAa,oCAAoC;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,eAAe;AACf,SAAS;AACT;;AAEA;AACA;AACA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA;AACA,yBAAyB,mBAAmB;AAC5C;AACA;AACA;AACA;AACA,2BAA2B;AAC3B,eAAe;AACf;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AAAA;AAAA;;;;;;;;;;;ACzVsB;AACA;;AAEtB;AACA;AACA;AACA,aAAa,SAAS;AACtB,aAAa,OAAO;AACpB,aAAa,aAAa;AAC1B;AACA,aAAa,aAAa;AAC1B;AACA,aAAa,oBAAoB;AACjC,aAAa,aAAa;AAC1B;AACA,uBAAuB,aAAa,KAAK;AACzC;AACA;AACA;;AAEA;AACA;AACA,mBAAmB,mBAAmB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,8BAA8B,kDAAkD;AAChF;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,mBAAmB,uBAAuB;AAC1C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,8BAA8B,kDAAkD;AAChF;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,8BAA8B,kDAAkD;AAChF;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;;;;;;;;;AC7FA;;AAEA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA,iBAAiB,mBAAmB;AACpC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,2CAA2C,4BAA4B;AACvE,yCAAyC,oBAAoB,GAAG,0BAA0B;AAC1F,MAAM,yBAAyB;AAC/B,+CAA+C,uBAAuB;AACtE,kCAAkC,sBAAsB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,YAAY,OAAO;AACnB,YAAY,SAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,yBAAyB;AACtC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,YAAY,gBAAgB;AAC5B,cAAc,QAAQ;AACtB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,YAAY,gBAAgB;AAC5B,aAAa,yBAAyB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,YAAY,OAAO;AACnB,YAAY,SAAS;AACrB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,YAAY,gBAAgB;AAC5B,YAAY,OAAO;AACnB,YAAY,SAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,YAAY,gBAAgB;AAC5B,YAAY,OAAO;AACnB,YAAY,SAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,YAAY,gBAAgB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,YAAY,OAAO;AACnB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA,mBAAmB,wBAAwB;AAC3C;AACA,qBAAqB,mBAAmB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,yCAAyC;AACxD;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA,mBAAmB,wBAAwB;AAC3C;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,wCAAwC;AACrD,YAAY,oCAAoC;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,kCAAkC;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,kCAAkC;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,YAAY,gBAAgB;AAC5B,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,qBAAqB,wBAAwB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,YAAY,OAAO;AACnB,YAAY,SAAS;AACrB,YAAY,OAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;;;;;;;;;;;;AC3QA;AAAA;AACA;AACA,WAAW,EAAE;AACb,YAAY,QAAQ;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW,EAAE;AACb,YAAY,QAAQ;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW,EAAE;AACb,YAAY,QAAQ;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW,EAAE;AACb,YAAY,QAAQ;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW,EAAE;AACb,YAAY,QAAQ;AACpB;AACA;AACA;AACA;;;;;;;;;;;AC3Ce;AACO;AACD;;AAErB;AACA;AACA;AACA,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,gCAAgC,kCAAkC;AAClE;AACA;AACA;AACA,eAAe;AACf;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,kCAAkC;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,wBAAwB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,cAAc;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,cAAc;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iBAAiB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,oBAAoB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,iBAAiB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,yBAAyB,kBAAkB;AAC3C;AACA;AACA,SAAS;AACT;AACA,yBAAyB,kBAAkB;AAC3C;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,mBAAmB,mBAAmB;AACtC;AACA;AACA;AACA;AACA;;AAEA;AACA,4BAA4B,kCAAkC;AAC9D;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,mBAAmB,mBAAmB;AACtC;AACA;AACA,4BAA4B,kCAAkC;AAC9D;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,eAAe;AAC9B;AACA;;AAEA;AACA,eAAe,eAAe;AAC9B;AACA,iBAAiB,eAAe;AAChC,oCAAoC;AACpC;AACA,SAAS;AACT;AACA;AACA,2BAA2B;;AAE3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,eAAe,MAAM;AACrB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,8CAA8C;AAC7D;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,yBAAyB;AACvD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iBAAiB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,eAAe,MAAM;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,2BAA2B,kBAAkB;AAC7C;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA,qBAAqB,mBAAmB;AACxC;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,uBAAuB,gBAAgB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sBAAsB;AAC1C;AACA;AACA;AACA,uBAAuB,mBAAmB;AAC1C;AACA,sBAAsB,yDAAyD;AAC/E;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA;;;;;;;;ACjcA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,+DAA+D;AAC/D;AACA;AACA;;AAEA;AACA;AACA,mBAAmB,mBAAmB;AACtC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA;;AAEA,6CAA6C;AAC7C;AACA;AACA;AACA,4BAA4B,kCAAkC;AAC9D;AACA;;AAEA,mCAAmC;AACnC;AACA;AACA;;AAEA;AACA,0BAA0B,kCAAkC;AAC5D;AACA,qBAAqB,8BAA8B;AACnD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,mBAAmB,mBAAmB;AACtC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,gCAAgC,QAAQ;AACxC;AACA;AACA;;AAEA;AACA;AACA,YAAY,OAAO;AACnB,YAAY,OAAO;AACnB,cAAc,OAAO;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AAAA;AAAA;;;;;;;;ACnJA;;GAEG;AACH,sCAAsC;AAEtC;;GAEG;AACG;IAGJ;;;OAGG;IACH,YAAY,IAAY,EAAE,IAAI,GAAG,EAAE;QACjC,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;QAClB,IAAI,CAAC,KAAK,CAAC,IAAI,GAAG,IAAI,CAAC;IACzB,CAAC;IAED;;;;;;;;OAQG;IACH,KAAK,CAAC,KAAa;QACjB,EAAE,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC;YACd,MAAM,SAAS,CAAC,kCAAkC,CAAC,CAAC;QACtD,CAAC;QACD,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,KAAK,CAAC;QACzB,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;IAED;;;OAGG;IACH,KAAK;QACH,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC;IACpB,CAAC;CACF;AAAA;AAAA;AAED;;;;;;;;;;;;;;GAcG;AACG,eAAiB,SAAQ,SAAS;IACtC;;;;OAIG;IACH,YAAY,KAAa,EAAE,IAAY,EAAE,OAAY,EAAE;QACrD,KAAK,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC;QACpB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,KAAK,CAAC;QACzB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,IAAI,CAAC;IAC1B,CAAC;CACF;AAAA;AAAA;AAED;;;;;;;;;;;;;;GAcG;AACG,gBAAkB,SAAQ,SAAS;IACvC;;;;OAIG;IACH,YAAY,KAAa,EAAE,KAAoB,EAAE,OAAY,EAAE;QAC7D,KAAK,CAAC,OAAO,EAAE,IAAI,CAAC,CAAC;QACrB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,KAAK,CAAC;QACzB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,KAAK,CAAC;IAC3B,CAAC;CACF;AAAA;AAAA;AAED;;;;;;;;;;;;;;;;;;;;;;;;;GAyBG;AACG,mBAAqB,SAAQ,SAAS;IAC1C;;;;OAIG;IACH,YAAY,KAAa,EAAE,QAAgB,EAAE,OAAY,EAAE;QACzD,KAAK,CAAC,UAAU,EAAE,IAAI,CAAC,CAAC;QACxB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,KAAK,CAAC;QACzB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,QAAQ,CAAC;IAC9B,CAAC;IAED;;;;OAIG;IACH,aAAa,CAAC,MAAe;QAC3B,IAAI,CAAC,KAAK,CAAC,cAAc,GAAG,MAAM,CAAC;QACnC,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;CACF;AAAA;AAAA;AAED;;;;;;;;;;;;;;;;;;;;;;;;GAwBG;AACG,gBAAkB,SAAQ,SAAS;IACvC;;;;OAIG;IACH,YAAY,KAAa,EAAE,KAAa,EAAE,OAAY,EAAE;QACtD,KAAK,CAAC,OAAO,EAAE,IAAI,CAAC,CAAC;QACrB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,KAAK,CAAC;QACzB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,KAAK,CAAC;IAC3B,CAAC;IAED;;;;;;;;;;OAUG;IACH,SAAS,CAAC,SAA0B;QAClC,EAAE,CAAC,CAAC,SAAS,KAAK,MAAM,IAAI,SAAS,GAAG,CAAC,CAAC,CAAC,CAAC;YAC1C,MAAM,SAAS,CAAC,8CAA8C,CAAC,CAAC;QAClE,CAAC;QACD,IAAI,CAAC,KAAK,CAAC,SAAS,GAAG,SAAS,CAAC;QACjC,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;IAED;;;;OAIG;IACH,YAAY,CAAC,YAAoB;QAC/B,EAAE,CAAC,CAAC,YAAY,GAAG,CAAC,CAAC,CAAC,CAAC;YACrB,MAAM,SAAS,CAAC,0CAA0C,CAAC,CAAC;QAC9D,CAAC;QACD,IAAI,CAAC,KAAK,CAAC,aAAa,GAAG,YAAY,CAAC;QACxC,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;CACF;AAAA;AAAA;AAED;;;;;;;;;;;;;;;;GAgBG;AACG,iBAAmB,SAAQ,SAAS;IACxC;;;;OAIG;IACH,YAAY,KAAa,EAAE,MAAc,EAAE,OAAY,EAAE;QACvD,KAAK,CAAC,QAAQ,EAAE,IAAI,CAAC,CAAC;QACtB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,KAAK,CAAC;QACzB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,MAAM,CAAC;IAC5B,CAAC;IAED;;;;OAIG;IACH,aAAa,CAAC,MAAe;QAC3B,IAAI,CAAC,KAAK,CAAC,cAAc,GAAG,MAAM,CAAC;QACnC,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;CACF;AAAA;AAAA;AAED;;;;;;;;;;;;;GAaG;AACG,iBAAmB,SAAQ,SAAS;IACxC;;;OAGG;IACH,YAAY,KAAa,EAAE,OAAY,EAAE;QACvC,KAAK,CAAC,QAAQ,EAAE,IAAI,CAAC,CAAC;QACtB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,KAAK,CAAC;IAC3B,CAAC;CACF;AAAA;AAAA;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;GA0BG;AACG,gBAAkB,SAAQ,SAAS;IACvC;;;;OAIG;IACH,YAAY,KAAa,EAAE,KAAa,EAAE,OAAY,EAAE;QACtD,KAAK,CAAC,OAAO,EAAE,IAAI,CAAC,CAAC;QACrB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,KAAK,CAAC;QACzB,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,KAAK,CAAC;IAC3B,CAAC;IAED;;;;;;;;;;;OAWG;IACH,kBAAkB,CAAC,cAAsB;QACvC,EAAE,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,QAAQ,KAAK,SAAS,IAAI,IAAI,CAAC,KAAK,CAAC,QAAQ,KAAK,KAAK,CAAC,CAAC,CAAC;YACvE,MAAM,WAAW,CAAC,0EAA0E,CAAC,CAAC;QAChG,CAAC;QACD,IAAI,CAAC,KAAK,CAAC,oBAAoB,GAAG,cAAc,CAAC;QACjD,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;IAED;;;;OAIG;IACH,QAAQ,CAAC,EAAU;QACjB,EAAE,CAAC,CAAC,EAAE,KAAK,KAAK,IAAI,EAAE,KAAK,IAAI,CAAC,CAAC,CAAC;YAChC,MAAM,WAAW,CAAC,mBAAmB,CAAC,CAAC;QACzC,CAAC;QACD,IAAI,CAAC,KAAK,CAAC,QAAQ,GAAG,EAAE,CAAC;QACzB,EAAE,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,oBAAoB,KAAK,SAAS,IAAI,IAAI,CAAC,KAAK,CAAC,QAAQ,KAAK,KAAK,CAAC,CAAC,CAAC;YACnF,MAAM,WAAW,CAAC,0EAA0E,CAAC,CAAC;QAChG,CAAC;QACD,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;IAED;;;;;;;;;;OAUG;IACH,SAAS,CAAC,SAA0B;QAClC,EAAE,CAAC,CAAC,SAAS,KAAK,MAAM,IAAI,SAAS,GAAG,CAAC,CAAC,CAAC,CAAC;YAC1C,MAAM,SAAS,CAAC,8CAA8C,CAAC,CAAC;QAClE,CAAC;QACD,IAAI,CAAC,KAAK,CAAC,SAAS,GAAG,SAAS,CAAC;QACjC,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;IAED;;;;OAIG;IACH,YAAY,CAAC,YAAoB;QAC/B,EAAE,CAAC,CAAC,YAAY,GAAG,CAAC,CAAC,CAAC,CAAC;YACrB,MAAM,SAAS,CAAC,0CAA0C,CAAC,CAAC;QAC9D,CAAC;QACD,IAAI,CAAC,KAAK,CAAC,aAAa,GAAG,YAAY,CAAC;QACxC,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;CACF;AAAA;AAAA;AAED;;;;;;;;;;;;;;;;;;GAkBG;AACG,mBAAqB,SAAQ,SAAS;IAC1C,YAAY,IAAI,GAAG,EAAE;QACnB,KAAK,CAAC,WAAW,EAAE,IAAI,CAAC,CAAC;IAC3B,CAAC;CACF;AAAA;AAAA;AAED;;;GAGG;AACH,gBAAiB,SAAQ,SAAS;IAIhC,YAAY,YAAoB,EAAE,QAAa,EAAE,OAAY,EAAE;QAC7D,KAAK,CAAC,OAAO,EAAE,IAAI,CAAC,CAAC;QACrB,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE,CAAC;QACvB,IAAI,CAAC,aAAa,GAAG,YAAY,CAAC;QAClC,IAAI,CAAC,YAAY,CAAC,GAAG,QAAQ,CAAC;QAE9B,IAAI,CAAC,QAAQ,GAAG,CAAC,SAAc,EAAE,GAAG,IAAW,EAAE,EAAE;YACjD,IAAI,IAAI,GAAG,EAAE,CAAC;YACd,IAAI,KAAK,GAAG,IAAI,SAAS,CAAC,GAAG,IAAI,EAAE,IAAI,CAAC,CAAC;YACzC,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAC7B,KAAK,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;YACvB,KAAK,CAAC,aAAa,GAAG,IAAI,CAAC,aAAa,CAAC;YACzC,KAAK,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;YACvB,KAAK,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;YACzB,KAAK,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC;YAC/B,KAAK,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;YACzB,KAAK,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;YACzB,KAAK,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC;YAC/B,KAAK,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC;YAC3B,KAAK,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC;YAC3B,KAAK,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC;YAC/B,KAAK,CAAC,IAAI,CAAC,aAAa,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC;YACrD,MAAM,CAAC,KAAK,CAAC;QACf,CAAC,CAAC;IACJ,CAAC;IAED,IAAI;QACF,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC;IAClC,CAAC;IAED,aAAa;QACX,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,kBAAkB,CAAC,CAAC;IAC3C,CAAC;IAED,IAAI,CAAC,KAAa,EAAE,IAAY;QAC9B,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,SAAS,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;IAC/C,CAAC;IAED,KAAK,CAAC,KAAa,EAAE,KAAoB;QACvC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,UAAU,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;IACjD,CAAC;IAED,QAAQ,CAAC,KAAa,EAAE,QAAgB;QACtC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,aAAa,EAAE,KAAK,EAAE,QAAQ,CAAC,CAAC;IACvD,CAAC;IAED,KAAK,CAAC,KAAa,EAAE,KAAa;QAChC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,UAAU,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;IACjD,CAAC;IAED,KAAK,CAAC,KAAa,EAAE,KAAa;QAChC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,UAAU,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;IACjD,CAAC;IAED,QAAQ;QACN,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,aAAa,CAAC,CAAC;IACtC,CAAC;IAED,MAAM,CAAC,KAAa,EAAE,MAAc;QAClC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,WAAW,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC;IACnD,CAAC;IAED,MAAM,CAAC,KAAa;QAClB,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,WAAW,EAAE,KAAK,CAAC,CAAC;IAC3C,CAAC;CACF;AAED;;;;;;;;;;;;;;;;;;;GAmBG;AACG,wBAA0B,SAAQ,SAAS;IAC/C,YAAY,OAAY,EAAE;QACxB,KAAK,CAAC,gBAAgB,EAAE,IAAI,CAAC,CAAC;IAChC,CAAC;IAED;;;OAGG;IACH,WAAW;QACT,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE,CAAC;QACvB,MAAM,CAAC,IAAI,UAAU,CAAC,WAAW,EAAE,GAAG,EAAE;YACtC,MAAM,CAAC,IAAI,CAAC;QACd,CAAC,EAAE,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;IACxB,CAAC;CACF;AAAA;AAAA;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA0CG;AACG,eAAiB,SAAQ,SAAS;IACtC,YAAY,OAAY,EAAE;QACxB,KAAK,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC;IACtB,CAAC;IAED;;;OAGG;IACH,SAAS;QACP,IAAI,CAAC,KAAK,CAAC,IAAI,GAAG,EAAE,CAAC;QACrB,MAAM,CAAC,IAAI,UAAU,CAAC,SAAS,EAAE,GAAG,EAAE;YACpC,MAAM,CAAC,IAAI,CAAC;QACd,CAAC,EAAE,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IACtB,CAAC;IAED;;;OAGG;IACH,WAAW;QACT,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE,CAAC;QACvB,MAAM,CAAC,IAAI,UAAU,CAAC,WAAW,EAAE,GAAG,EAAE;YACtC,MAAM,CAAC,IAAI,CAAC;QACd,CAAC,EAAE,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;IACxB,CAAC;IAED;;;OAGG;IACH,WAAW;QACT,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE,CAAC;QACvB,MAAM,CAAC,IAAI,UAAU,CAAC,WAAW,EAAE,GAAG,EAAE;YACtC,MAAM,CAAC,IAAI,CAAC;QACd,CAAC,EAAE,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;IACxB,CAAC;IAED;;;OAGG;IACH,QAAQ;QACN,IAAI,CAAC,KAAK,CAAC,GAAG,GAAG,EAAE,CAAC;QACpB,MAAM,CAAC,IAAI,UAAU,CAAC,QAAQ,EAAE,GAAG,EAAE;YACnC,MAAM,CAAC,IAAI,CAAC;QACd,CAAC,EAAE,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;IACrB,CAAC;IAED;;;;;;;;;;;OAWG;IACH,kBAAkB,CAAC,cAAsB;QACvC,IAAI,CAAC,KAAK,CAAC,oBAAoB,GAAG,cAAc,CAAC;QACjD,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;CACF;AAAA;AAAA;AAED;;;;;;;;;;;;;;;;;;GAkBG;AACG;IAIJ;QACE,IAAI,CAAC,KAAK,GAAG,EAAC,KAAK,EAAE,EAAE,EAAC,CAAC;QACzB,IAAI,CAAC,OAAO,EAAE,CAAC;IACjB,CAAC;IAED;;;;OAIG;IACH,kBAAkB,CAAC,MAAe;QAChC,IAAI,CAAC,KAAK,CAAC,aAAa,GAAG,MAAM,CAAC;QAClC,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;IAED;;;;;;;;;;;OAWG;IACH,OAAO,CAAC,KAAa,GAAG,EAAE,IAAY,IAAI;QACxC,EAAE,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,CAAC,CAAC;YACX,MAAM,SAAS,CAAC,qCAAqC,CAAC,CAAC;QACzD,CAAC;QACD,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;YACnB,MAAM,SAAS,CAAC,qDAAqD,CAAC,CAAC;QACzE,CAAC;QAED,IAAI,CAAC,KAAK,CAAC,OAAO,GAAG;YACnB,IAAI,EAAE,MAAM;YACZ,EAAE;YACF,CAAC;SACF,CAAC;QACF,MAAM,CAAC,IAAI,CAAC;IACd,CAAC;IAED,IAAI;QACF,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC;IAClC,CAAC;IAED,aAAa;QACX,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,kBAAkB,CAAC,CAAC;IAC3C,CAAC;IAED,IAAI,CAAC,KAAa,EAAE,IAAY;QAC9B,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,SAAS,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;IAC/C,CAAC;IAED,KAAK,CAAC,KAAa,EAAE,KAAoB;QACvC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,UAAU,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;IACjD,CAAC;IAED,QAAQ,CAAC,KAAa,EAAE,QAAgB;QACtC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,aAAa,EAAE,KAAK,EAAE,QAAQ,CAAC,CAAC;IACvD,CAAC;IAED,KAAK,CAAC,KAAa,EAAE,KAAa;QAChC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,UAAU,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;IACjD,CAAC;IAED,KAAK,CAAC,KAAa,EAAE,KAAa;QAChC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,UAAU,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;IACjD,CAAC;IAED,QAAQ;QACN,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,aAAa,CAAC,CAAC;IACtC,CAAC;IAED,MAAM,CAAC,KAAa,EAAE,MAAc;QAClC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,WAAW,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC;IACnD,CAAC;IAED,MAAM,CAAC,KAAa;QAClB,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,WAAW,EAAE,KAAK,CAAC,CAAC;IAC3C,CAAC;IAED,QAAQ,CAAC,SAAc,EAAE,GAAG,IAAW;QACrC,IAAI,CAAC,MAAM,GAAG,IAAI,SAAS,CAAC,GAAG,IAAI,EAAE,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;QACvD,IAAI,CAAC,MAAM,CAAC,KAAK,GAAG,GAAG,EAAE;YACvB,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC;QACpB,CAAC,CAAC;QACF,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC;IACrB,CAAC;CACF;AAAA;AAAA","file":"lokijs.full-text-search.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"@lokijs/full-text-search\"] = factory();\n\telse\n\t\troot[\"@lokijs/full-text-search\"] = factory();\n})(this, function() {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 1);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap c70048379539057bd6e9","import {Tokenizer} from \"./tokenizer\";\n\n/**\n * Inverted index class handles featured text search for specific document fields.\n * @constructor InvertedIndex\n * @param {boolean} [options.store=true] - inverted index will be stored at serialization rather than rebuilt on load.\n */\nexport class InvertedIndex {\n  /**\n   * @param {boolean} store\n   * @param {boolean} optimizeChanges\n   * @param {Tokenizer} tokenizer\n   */\n  constructor({store = true, optimizeChanges = true, tokenizer = new Tokenizer} = {}) {\n    this._store = store;\n    this._optimizeChanges = optimizeChanges;\n    this._tokenizer = tokenizer;\n    this._docCount = 0;\n    this._docStore = {};\n    this._totalFieldLength = 0;\n    this._root = {};\n  }\n\n  get store() {\n    return this._store;\n  }\n\n  get tokenizer() {\n    return this._tokenizer;\n  }\n\n  get documentCount() {\n    return this._docCount;\n  }\n\n  get documentStore() {\n    return this._docStore;\n  }\n\n  get totalFieldLength() {\n    return this._totalFieldLength;\n  }\n\n  get root() {\n    return this._root;\n  }\n\n  /**\n   * Adds defined fields of a document to the inverted index.\n   * @param {object} field - the field to add\n   * @param {number} docId - the doc id of the field\n   */\n  insert(field, docId) {\n    if (this._docStore[docId] !== undefined) {\n      throw Error(\"Field already added.\");\n    }\n\n    this._docCount += 1;\n    this._docStore[docId] = {};\n\n    // Tokenize document field.\n    let fieldTokens = this._tokenizer.tokenize(field);\n    this._totalFieldLength += fieldTokens.length;\n\n    let termRefs = [];\n    this._docStore[docId] = {fieldLength: fieldTokens.length};\n    if (this._optimizeChanges) {\n      Object.defineProperties(this._docStore[docId], {\n        termRefs: {enumerable: false, configurable: true, writable: true, value: termRefs}\n      });\n    }\n\n    // Iterate over all unique field terms.\n    for (let term of new Set(fieldTokens)) {\n      if (term === \"\") {\n        continue;\n      }\n      // Calculate term frequency.\n      let tf = 0;\n      for (let j = 0; j < fieldTokens.length; j++) {\n        if (fieldTokens[j] === term) {\n          tf++;\n        }\n      }\n\n      // Add term to index tree.\n      let branch = this._root;\n      for (let i = 0; i < term.length; i++) {\n        let c = term[i];\n        if (branch[c] === undefined) {\n          let child = {};\n          if (this._optimizeChanges) {\n            Object.defineProperties(child, {\n              pa: {enumerable: false, configurable: true, writable: true, value: branch}\n            });\n          }\n          branch[c] = child;\n        }\n        branch = branch[c];\n      }\n      // Add term info to index leaf.\n      if (branch.dc === undefined) {\n        branch.dc = {};\n        branch.df = 0;\n      }\n      branch.dc[docId] = tf;\n      branch.df += 1;\n\n      // Store index leaf for deletion.\n      termRefs.push(branch);\n    }\n  }\n\n  /**\n   * Removes all relevant terms of a document from the inverted index.\n   * @param {number} docId - the document.\n   */\n  remove(docId) {\n    if (this._docStore[docId] === undefined) {\n      return;\n    }\n    let docStore = this._docStore[docId];\n    // Remove document.\n    delete this._docStore[docId];\n    this._docCount -= 1;\n\n    // Reduce total field length.\n    this._totalFieldLength -= docStore.fieldLength;\n\n    if (this._optimizeChanges) {\n      // Iterate over all term references.\n      // Remove docId from docs and decrement document frequency.\n      let termRefs = docStore.termRefs;\n      for (let j = 0; j < termRefs.length; j++) {\n        let index = termRefs[j];\n        index.df -= 1;\n        delete index.dc[docId];\n\n        // Check if no document is left for current tree.\n        if (index.df === 0) {\n          // Delete unused meta data of branch.\n          delete index.df;\n          delete index.dc;\n\n          // Check for sub branches.\n          if (Object.keys(index).length !== 0) {\n            continue;\n          }\n\n          // Delete term branch if not used anymore.\n          let keys = [];\n          do {\n            // Go tree upwards.\n            let parent = index.pa;\n            // Delete parent reference for preventing memory leak (cycle reference).\n            delete index.pa;\n\n            // Iterate over all children.\n            keys = Object.keys(parent);\n            for (let k = 0; k < keys.length; k++) {\n              let key = keys[k];\n              if (key.length !== 1) {\n                continue;\n              }\n              // Remove previous child form parent.\n              if (parent[key] === index) {\n                delete parent[key];\n                break;\n              }\n            }\n            index = parent;\n          } while (index.pa !== undefined && keys.length === 1);\n        }\n      }\n    } else {\n      // Iterate over the whole inverted index and remove the document.\n      // Delete branch if not needed anymore.\n      let recursive = (root) => {\n        let keys = Object.keys(root);\n        for (let i = 0; i < keys.length; i++) {\n          let key = keys[i];\n          if (key.length === 1) {\n            // Checkout branch.\n            if (recursive(root[key])) {\n              delete root[key];\n            }\n          }\n        }\n        // Remove docId from docs and decrement document frequency.\n        if (root.df !== undefined) {\n          if (root.dc[docId] !== undefined) {\n            root.df -= 1;\n            delete root.dc[docId];\n\n            // Delete unused meta data of branch.\n            if (root.df === 0) {\n              delete root.df;\n              delete root.dc;\n            }\n          }\n        }\n        return Object.keys(root).length === 0;\n      };\n      recursive(this._root);\n    }\n  }\n\n  /**\n   * Gets the term index of a term.\n   * @param {string} term - the term.\n   * @param {object} root - the term index to start from\n   * @param {number} start - the position of the term string to start from\n   * @return {object} - The term index or null if the term is not in the term tree.\n   */\n  static getTermIndex(term, root, start = 0) {\n    if (start >= term.length) {\n      return null;\n    }\n    for (let i = start; i < term.length; i++) {\n      if (root[term[i]] === undefined) {\n        return null;\n      }\n      root = root[term[i]];\n    }\n    return root;\n  }\n\n  /**\n   * Extends a term index for the one branch.\n   * @param {object} root - the term index to start from\n   * @return {Array} - array with term indices and extension\n   */\n  static getNextTermIndex(root) {\n    let termIndices = [];\n    let keys = Object.keys(root);\n    for (let i = 0; i < keys.length; i++) {\n      if (keys[i].length === 1) {\n        termIndices.push({index: root[keys[i]], term: keys[i]});\n      }\n    }\n    return termIndices;\n  }\n\n  /**\n   * Extends a term index to all available term leafs.\n   * @param {object} root - the term index to start from\n   * @returns {Array} - Array with term indices and extension\n   */\n  static extendTermIndex(root) {\n    let termIndices = [];\n    let stack = [root];\n    let treeStack = [\"\"];\n    do {\n      let root = stack.pop();\n      let treeTermn = treeStack.pop();\n\n      if (root.df !== undefined) {\n        termIndices.push({index: root, term: treeTermn});\n      }\n\n      let keys = Object.keys(root);\n      for (let i = 0; i < keys.length; i++) {\n        if (keys[i].length === 1) {\n          stack.push(root[keys[i]]);\n          treeStack.push(treeTermn + keys[i]);\n        }\n      }\n    } while (stack.length !== 0);\n\n    return termIndices;\n  }\n\n  /**\n   * Serialize the inverted index.\n   * @returns {{docStore: *, _fields: *, index: *}}\n   */\n  toJSON() {\n    if (this._store) {\n      return this;\n    } else {\n      return {\n        _store: false,\n        _optimizeChanges: this._optimizeChanges,\n        _tokenizer: this._tokenizer\n      };\n    }\n  }\n\n  /**\n   * Deserialize the inverted index.\n   * @param {{docStore: *, _fields: *, index: *}} serialized - The serialized inverted index.\n   * @param {Object.<string, function>|Tokenizer} funcTok[undefined] - the depending functions with labels\n   *  or an equivalent tokenizer\n   */\n  static fromJSONObject(serialized, funcTok = undefined) {\n    let dbObject = serialized;\n    let invIdx = new InvertedIndex({\n      store: dbObject._store,\n      optimizeChanges: dbObject._optimizeChanges,\n      tokenizer: Tokenizer.fromJSONObject(dbObject._tokenizer, funcTok)\n    });\n    invIdx._docCount = dbObject._docCount;\n    invIdx._docStore = dbObject._docStore;\n    invIdx._totalFieldLength = dbObject._totalFieldLength;\n    invIdx._root = dbObject._root;\n\n    let regenerate = (index, parent) => {\n      // Set parent.\n      if (parent !== null) {\n        Object.defineProperties(index, {\n          pa: {enumerable: false, configurable: true, writable: false, value: parent}\n        });\n      }\n\n      // Iterate over all keys.\n      let keys = Object.keys(index);\n      for (let i = 0; i < keys.length; i++) {\n        // Found term, save in document store.\n        if (keys[i] === \"dc\") {\n          // Get documents of term.\n          let docIds = Object.keys(index.dc);\n          for (let j = 0; j < docIds.length; j++) {\n            // Get document store at specific document/field.\n            let ref = invIdx._docStore[docIds[j]];\n            if (ref.termRefs === undefined) {\n              Object.defineProperties(ref, {\n                termRefs: {enumerable: false, configurable: true, writable: true, value: []}\n              });\n            }\n            // Set reference to term index.\n            ref.termRefs.push(index);\n          }\n        } else if (keys[i].length === 1) {\n          // Iterate over subtree.\n          regenerate(index[keys[i]], index);\n        }\n      }\n    };\n\n    if (invIdx._optimizeChanges) {\n      regenerate(invIdx._root, null);\n    }\n\n    return invIdx;\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./packages/full-text-search/src/inverted_index.js\n// module id = 0\n// module chunks = 0","import {InvertedIndex} from \"./inverted_index\";\nimport {IndexSearcher} from \"./index_searcher\";\n\nexport class FullTextSearch {\n  /**\n   * Initialize the full text search for the given fields.\n   * @param {object[]} fields - the field options\n   * @param {string} fields.name - the name of the field\n   * @param {boolean=true} fields.store - flag to indicate if the full text search should be stored on serialization or\n   *  rebuild on deserialization\n   * @param {boolean=true} fields.optimizeChanges - flag to indicate if deleting/updating a document should be optimized\n   *  (requires more memory but performs better)\n   * @param {Tokenizer=Tokenizer} fields.tokenizer - the tokenizer of the field\n   * @param {string=$loki} id - the property name of the document index\n   */\n  constructor(fields, {id = \"$loki\"} = {}) {\n    if (fields === undefined) {\n      throw new SyntaxError(\"Fields needs to be defined!\");\n    }\n\n    this._invIdxs = {};\n    // Create inverted indices for each field.\n    for (let i = 0; i < fields.length; i++) {\n      let field = fields[i];\n      this._invIdxs[field.name] = new InvertedIndex(field);\n    }\n    this._id = id;\n    this._docs = new Set();\n    this._idxSearcher = new IndexSearcher(this._invIdxs, this._docs);\n  }\n\n  addDocument(doc) {\n    if (doc[this._id] === undefined) {\n      throw new Error(\"Document is not stored in the collection.\");\n    }\n\n    let fieldNames = Object.keys(doc);\n    for (let i = 0, fieldName; i < fieldNames.length, fieldName = fieldNames[i]; i++) {\n      if (this._invIdxs[fieldName] !== undefined) {\n        this._invIdxs[fieldName].insert(doc[fieldName], doc[this._id]);\n      }\n    }\n\n    this._docs.add(doc[this._id]);\n    this.setDirty();\n  }\n\n  removeDocument(doc) {\n    if (doc[this._id] === undefined) {\n      throw new Error(\"Document is not stored in the collection.\");\n    }\n\n    let fieldNames = Object.keys(this._invIdxs);\n    for (let i = 0; i < fieldNames.length; i++) {\n      this._invIdxs[fieldNames[i]].remove(doc[this._id]);\n    }\n\n    this._docs.delete(doc[this._id]);\n    this.setDirty();\n  }\n\n  updateDocument(doc) {\n    this.removeDocument(doc);\n    this.addDocument(doc);\n  }\n\n  search(query) {\n    return this._idxSearcher.search(query);\n  }\n\n  toJSON() {\n    let serialized = {};\n    let fieldNames = Object.keys(this._invIdxs);\n    for (let i = 0, fieldName; i < fieldNames.length, fieldName = fieldNames[i]; i++) {\n      serialized[fieldName] = this._invIdxs[fieldName].toJSON();\n    }\n    return serialized;\n  }\n\n  static fromJSONObject(serialized, tokenizers) {\n    let db = JSON.parse(serialized);\n    let fts = new FullTextSearch();\n    let fieldNames = Object.keys(db);\n    for (let i = 0, fieldName; i < fieldNames.length, fieldName = fieldNames[i]; i++) {\n      fts._invIdxs[fieldName] = new InvertedIndex();\n      fts._invIdxs[fieldName].loadJSON(db[fieldName], tokenizers[fieldName]);\n    }\n    return fts;\n  }\n\n  setDirty() {\n    this._idxSearcher.setDirty();\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./packages/full-text-search/src/full_text_search.js\n// module id = 1\n// module chunks = 0","import * as Utils from \"./utils.js\";\n\n/**\n * Splits a string at non-alphanumeric characters into lower case tokens.\n * @param {string} str - the string\n * @returns {string[]} - the tokens\n * @private\n */\nfunction defaultSplitter(str) {\n  let tokens = str.split(/[^\\w]+/);\n  for (let i = 0; i < tokens.length; i++) {\n    tokens[i] = tokens[i].toLowerCase();\n  }\n  return tokens;\n}\n\n/**\n * The tokenizer is used to prepare the string content of a document field for the inverted index.\n * Firstly the string gets split into tokens.\n * After that the tokens will be trimmed/stemmed with defined functions from the queue.\n *\n * * To change the splitter function, use {@link Tokenizer#setSplitter}.\n * * To add functions to the queue, use {@link Tokenizer#add}, {@link Tokenizer#addBefore} and\n *   {@link Tokenizer#addAfter}.\n * * To remove a function from the queue, use {@link Tokenizer#remove}.\n * * To reset the tokenizer, use {@link Tokenizer#reset}.\n */\nexport class Tokenizer {\n  /**\n\t * Initializes the tokenizer with a splitter, which splits a string at non-alphanumeric characters.\n\t * The queue is empty.\n\t */\n  constructor() {\n    this._splitter = null;\n    this._queue = [];\n    this._symbol = Symbol(\"label\");\n    this.reset();\n  }\n\n  /**\n\t * Sets a function with defined label as the splitter function.\n\t * The function must take a string as argument and return an array of tokens.\n\t *\n\t * @param {string} label - the label\n\t * @param {function} func - the function\n\t */\n  setSplitter(label, func) {\n    if (label === \"\") {\n      throw Error(\"Label cannot be empty.\");\n    }\n    func[this._symbol] = label;\n    this._splitter = func;\n  }\n\n  /**\n\t * Gets the splitter.\n\t * @return {Array.<string, function>} - tuple with label and function\n\t */\n  getSplitter() {\n    return [this._splitter[this._symbol], this._splitter];\n  }\n\n  /**\n\t * Resets the splitter to default.\n\t */\n  resetSplitter() {\n    this._splitter = defaultSplitter;\n  }\n\n  /**\n\t * Checks if a function is inside the queue.\n\t * @param {string|function} labelFunc - an existing label or function\n\t * @returns {boolean} true if exists, otherwise false\n\t */\n  has(labelFunc) {\n    return this._getPosition(labelFunc) !== -1;\n  }\n\n  /**\n\t * Gets a function from the queue.\n\t * Only the first found function gets returned if a label or a function is multiple used.\n\t *\n\t * @param {string|function} labelFunc - an existing label or function\n\t * @return {Array.<string, function>} - tuple with label and function\n\t */\n  get(labelFunc) {\n    let pos = this._getPosition(labelFunc);\n    if (pos === -1) {\n      throw Error(\"Cannot find existing function.\");\n    }\n    return [this._queue[pos][this._symbol], this._queue[pos]];\n  }\n\n  /**\n\t * Adds a function with defined label to the end of the queue.\n\t * The function must take a token string as argument and return a token.\n\t *\n\t * @param {string} label - the label\n\t * @param {function} func - the function\n\t */\n  add(label, func) {\n    this._addFunction(label, func, this._queue.length);\n  }\n\n  /**\n\t * Adds a function with defined label before an existing function to the queue.\n\t * The function must take a token string as argument and return a token.\n\t *\n\t * @param {string|function} labelFunc - an existing label or function\n\t * @param {string} label - the label\n\t * @param {function} func - the function\n\t */\n  addBefore(labelFunc, label, func) {\n    let pos = this._getPosition(labelFunc);\n    if (pos === -1) {\n      throw Error(\"Cannot find existing function.\");\n    }\n    this._addFunction(label, func, pos);\n  }\n\n  /**\n\t * Adds a function with defined label after an existing function to the queue.\n\t * The function must take a token string as argument and return a token.\n\t *\n\t * @param {string|function} labelFunc - an existing label or function\n\t * @param {string} label - the label\n\t * @param {function} func - the function\n\t */\n  addAfter(labelFunc, label, func) {\n    let pos = this._getPosition(labelFunc);\n    if (pos === -1) {\n      throw Error(\"Cannot find existing function.\");\n    }\n    this._addFunction(label, func, pos + 1);\n  }\n\n  /**\n\t * Removes a function from the queue.\n\t * @param {string|function} labelFunc - an existing label or function\n\t */\n  remove(labelFunc) {\n    let pos = this._getPosition(labelFunc);\n    if (pos === -1) {\n      throw Error(\"Cannot find existing function.\");\n    }\n    this._queue.splice(pos, 1);\n  }\n\n  /**\n\t * Resets the splitter and tokenize queue to default.\n\t */\n  reset() {\n    this._splitter = defaultSplitter;\n    this._queue = [];\n  }\n\n  /**\n\t * Tokenizes a string into tokens.\n\t * @param {string} str - the string\n\t * @return {string[]} the tokens\n\t */\n  tokenize(str) {\n    let tokens = this._splitter(str);\n    // Apply each token over the queue functions.\n    for (let i = 0; i < this._queue.length; i++) {\n      let newTokens = [];\n      for (let j = 0; j < tokens.length; j++) {\n        let token = this._queue[i](tokens[j]);\n        if (token) {\n          newTokens.push(token);\n        }\n      }\n      tokens = newTokens;\n    }\n    return tokens;\n  }\n\n  /**\n\t * Serializes the tokenizer by returning the labels of the used functions.\n\t * @returns {{splitter: string?, tokenizers: string[]}} - the serialization\n\t * @private\n\t */\n  toJSON() {\n    let serialized = {tokenizers: []};\n    if (this._splitter !== defaultSplitter) {\n      serialized.splitter = this._splitter[this._symbol];\n    }\n    for (let i = 0; i < this._queue.length; i++) {\n      serialized.tokenizers.push(this._queue[i][this._symbol]);\n    }\n    return serialized;\n  }\n\n  /**\n\t * Deserializes the tokenizer by reassign the correct function to each label.\n\t * @param {{splitter: string, tokenizers: string[]}} serialized - the serialized labels\n\t * @param {Object.<string, function>|Tokenizer} funcTok - the depending functions with labels\n\t * \tor an equivalent tokenizer\n\t */\n  static fromJSONObject(serialized, funcTok) {\n    let tkz = new Tokenizer();\n    if (funcTok !== undefined && funcTok instanceof Tokenizer) {\n      if (serialized.splitter !== undefined) {\n        let splitter = funcTok.getSplitter();\n        if (serialized.splitter !== splitter[0]) {\n          throw Error(\"Splitter function not found.\");\n        }\n        tkz.setSplitter(splitter[0], splitter[1]);\n      }\n\n      for (let i = 0; i < serialized.tokenizers.length; i++) {\n        if (!funcTok.has(serialized.tokenizers[i])) {\n          throw Error(\"Tokenizer function not found.\");\n        }\n        let labelFunc = funcTok.get(serialized.tokenizers[i]);\n        tkz.add(labelFunc[0], labelFunc[1]);\n      }\n    } else {\n      if (serialized.splitter !== undefined) {\n        if (funcTok.splitters[serialized.splitter] === undefined) {\n          throw Error(\"Splitter function not found.\");\n        }\n        tkz.setSplitter(serialized.splitter, funcTok.splitters[serialized.splitter]);\n      }\n      for (let i = 0; i < serialized.tokenizers.length; i++) {\n        if (funcTok.tokenizers[serialized.tokenizers[i]] === undefined) {\n          throw Error(\"Tokenizer function not found.\");\n        }\n        tkz.add(serialized.tokenizers[i], funcTok.tokenizers[serialized.tokenizers[i]]);\n      }\n    }\n    return tkz;\n  }\n\n  /**\n\t * Returns the position of a function inside the queue.\n\t * @param {string|function} labelFunc - an existing label or function\n\t * @return {number} the position\n\t * @private\n\t */\n  _getPosition(labelFunc) {\n    if (Utils.isFunction(labelFunc)) {\n      return this._queue.indexOf(labelFunc);\n    } else {\n      for (let i = 0; i < this._queue.length; i++) {\n        if (this._queue[i][this._symbol] === labelFunc) {\n          return i;\n        }\n      }\n    }\n    return -1;\n  }\n\n  /**\n\t * Adds a function with defined label at a specific position to the queue.\n\t * @param {string} label - the label\n\t * @param {function} func - the function\n\t * @param {number} pos - the position\n\t * @private\n\t */\n  _addFunction(label, func, pos) {\n    if (label === \"\") {\n      throw Error(\"Label cannot be empty.\");\n    }\n    func[this._symbol] = label;\n    this._queue.splice(pos, 0, func);\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./packages/full-text-search/src/tokenizer.js\n// module id = 2\n// module chunks = 0","/**\n * Checks if the variable is a function.\n * @param {*} x - the variable\n * @return {boolean} true if function, otherwise false\n */\nexport function isFunction(x) {\n  return Object.prototype.toString.call(x) === \"[object Function]\";\n}\n\n/**\n * Checks if the variable is an object.\n * @param {*} x - the variable\n * @return {boolean} true if object, otherwise false\n */\nexport function isObject(x) {\n  return Object.prototype.toString.call(x) === \"[object Object]\";\n}\n\n/**\n * Checks if the variable is a number.\n * @param {*} x - the variable\n * @return {boolean} true if number, otherwise false\n */\nexport function isNumber(x) {\n  return Object.prototype.toString.call(x) === \"[object Number]\";\n}\n\n/**\n * Checks if the variable is a boolean.\n * @param {*} x - the variable\n * @return {boolean} true if boolean, otherwise false\n */\nexport function isBoolean(x) {\n  return Object.prototype.toString.call(x) === \"[object Boolean]\";\n}\n\n/**\n * Checks if the variable is a string.\n * @param {*} x - the variable\n * @return {boolean} true if string, otherwise false\n */\nexport function isString(x) {\n  return Object.prototype.toString.call(x) === \"[object String]\";\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./packages/full-text-search/src/utils.js\n// module id = 3\n// module chunks = 0","import {Scorer} from \"./scorer\";\nimport {InvertedIndex} from \"./inverted_index\";\nimport {QueryBuilder} from \"./queries\";\n\nexport class IndexSearcher {\n  /**\n   *\n   * @param {object} invIdxs\n   */\n  constructor(invIdxs, docs) {\n    this._invIdxs = invIdxs;\n    this._docs = docs;\n    this._scorer = new Scorer(this._invIdxs);\n  }\n\n  search(query) {\n    let docResults = this._recursive(query.query, true);\n\n    // Final scoring.\n    let finalScoring = query.final_scoring !== undefined ? query.final_scoring : true;\n    if (finalScoring) {\n      return this._scorer.finalScore(query, docResults);\n    }\n    return docResults;\n  }\n\n  setDirty() {\n    this._scorer.setDirty();\n  }\n\n  _recursive(query, doScoring) {\n    let docResults = {};\n    let boost = query.boost !== undefined ? query.boost : 1;\n    let fieldName = query.field !== undefined ? query.field : null;\n    let enableScoring = query.enable_scoring !== undefined ? query.enable_scoring : false;\n\n    let root = null;\n    let tokenizer = null;\n    if (this._invIdxs[fieldName] !== undefined) {\n      root = this._invIdxs[fieldName].root;\n      tokenizer = this._invIdxs[fieldName].tokenizer;\n    }\n\n    switch (query.type) {\n      case \"bool\": {\n        docResults = null;\n        if (query.must !== undefined) {\n          docResults = this._getUnique(query.must.values, doScoring, docResults);\n        }\n        if (query.filter !== undefined) {\n          docResults = this._getUnique(query.filter.values, false, docResults);\n        }\n\n        if (query.should !== undefined) {\n          let shouldDocs = this._getAll(query.should.values, doScoring);\n\n          let empty = false;\n          if (docResults === null) {\n            docResults = {};\n            empty = true;\n          }\n\n          let msm = 1;\n          // TODO: Enable percent and ranges.\n          if (query.minimum_should_match !== undefined) {\n            msm = query.minimum_should_match;\n            let shouldLength = query.should.values.length;\n            if (msm <= -1) {\n              msm = shouldLength + msm;\n            } else if (msm < 0) {\n              msm = shouldLength - Math.floor(shouldLength * -msm);\n            } else if (msm < 1) {\n              msm = Math.floor(shouldLength * msm);\n            }\n          }\n          // Remove all docs with fewer matches.\n          let docs = Object.keys(shouldDocs);\n          for (let i = 0, docId; i < docs.length, docId = docs[i]; i++) {\n            if (shouldDocs[docId].length >= msm) {\n              if (docResults[docId] !== undefined) {\n                docResults[docId].push(...shouldDocs[docId]);\n              } else if (empty) {\n                docResults[docId] = shouldDocs[docId];\n              } else {\n                delete docResults[docId];\n              }\n            }\n          }\n        }\n        if (query.not !== undefined) {\n          let notDocs = this._getAll(query.not.values, false);\n          // Remove all docs.\n          let docs = Object.keys(notDocs);\n          for (let i = 0, docId; i < docs.length, docId = docs[i]; i++) {\n            if (docResults[docId] !== undefined) {\n              delete docResults[docId];\n            }\n          }\n        }\n        break;\n      }\n      case \"term\": {\n        let termIdx = InvertedIndex.getTermIndex(query.value, root);\n        this._scorer.prepare(fieldName, boost, termIdx, doScoring, docResults, query.value);\n        break;\n      }\n      case \"terms\": {\n        for (let i = 0; i < query.value.length; i++) {\n          let termIdx = InvertedIndex.getTermIndex(query.value[i], root);\n          this._scorer.prepare(fieldName, boost, termIdx, doScoring, docResults, query.value[i]);\n        }\n        break;\n      }\n      case \"fuzzy\": {\n        let f = new FuzzySearch(query);\n        let b = f.search(root);\n        for (let i = 0; i < b.length; i++) {\n          this._scorer.prepare(fieldName, boost * b[i].boost, b[i].index, doScoring, docResults, b[i].term);\n        }\n        break;\n      }\n      case \"wildcard\": {\n        let w = new WildcardSearch(query);\n        let a = w.search(root);\n        for (let i = 0; i < a.length; i++) {\n          this._scorer.prepare(fieldName, boost, a[i].index, doScoring && enableScoring, docResults, a[i].term);\n        }\n        break;\n      }\n      case \"match_all\": {\n        for (let docId of this._docs) {\n          this._scorer.scoreConstant(boost, docId, docResults);\n        }\n        break;\n      }\n      case \"constant_score\": {\n        let tmpDocResults = this._getAll(query.filter.values, false);\n        let docs = Object.keys(tmpDocResults);\n        // Add to each document a constant score.\n        for (let i = 0; i < docs.length; i++) {\n          this._scorer.scoreConstant(boost, docs[i], docResults);\n        }\n        break;\n      }\n      case \"prefix\": {\n        let termIdx = InvertedIndex.getTermIndex(query.value, root);\n        if (termIdx !== null) {\n          termIdx = InvertedIndex.extendTermIndex(termIdx);\n          for (let i = 0; i < termIdx.length; i++) {\n            this._scorer.prepare(fieldName, boost, termIdx[i].index, doScoring && enableScoring, docResults, query.value + termIdx[i].term);\n          }\n        }\n        break;\n      }\n      case \"exists\": {\n        if (root !== null) {\n          let docs = Object.keys(this._invIdxs[fieldName].documentStore);\n          for (let i = 0; i < docs.length; i++) {\n            this._scorer.scoreConstant(boost, docs[i], docResults);\n          }\n        }\n        break;\n      }\n      case \"match\": {\n        let terms = tokenizer.tokenize(query.value);\n        let operator = query.operator !== undefined ? query.operator : \"or\";\n\n        let tmpQuery = new QueryBuilder().bool();\n        if (operator === \"or\") {\n          if (query.minimum_should_match !== undefined) {\n            tmpQuery = tmpQuery.minimumShouldMatch(query.minimum_should_match);\n          }\n          // Build a should query.\n          tmpQuery = tmpQuery.beginShould();\n        } else {\n          // Build a must query.\n          tmpQuery = tmpQuery.beginMust();\n        }\n        tmpQuery = tmpQuery.boost(boost);\n\n        if (query.fuzziness !== undefined) {\n          let prefixLength = query.prefix_length !== undefined ? query.prefix_length : 2;\n          // Add each fuzzy.\n          for (let i = 0; i < terms.length; i++) {\n            tmpQuery = tmpQuery.fuzzy(fieldName, terms[i]).fuzziness(query.fuzziness).prefixLength(prefixLength);\n          }\n        } else {\n          // Add each term.\n          for (let i = 0; i < terms.length; i++) {\n            tmpQuery = tmpQuery.term(fieldName, terms[i]);\n          }\n        }\n        if (operator === \"or\") {\n          tmpQuery = tmpQuery.endShould();\n        } else {\n          tmpQuery = tmpQuery.endMust();\n        }\n        docResults = this._recursive(tmpQuery.build().query, doScoring);\n\n        break;\n      }\n      default:\n        break;\n    }\n    return docResults;\n  }\n\n  _getUnique(values, doScoring, docResults) {\n    if (values.length === 0) {\n      return docResults;\n    }\n\n    for (let i = 0; i < values.length; i++) {\n      let currDocs = this._recursive(values[i], doScoring);\n      if (docResults === null) {\n        docResults = this._recursive(values[0], doScoring);\n        continue;\n      }\n\n      let docs = Object.keys(docResults);\n      for (let j = 0, docId; j < docs.length, docId = docs[j]; j++) {\n        if (currDocs[docId] === undefined) {\n          delete docResults[docId];\n        } else {\n          docResults[docId].push(...currDocs[docId]);\n        }\n      }\n    }\n    return docResults;\n  }\n\n  _getAll(values, doScoring) {\n    let docResults = {};\n    for (let i = 0; i < values.length; i++) {\n      let currDocs = this._recursive(values[i], doScoring);\n      let docs = Object.keys(currDocs);\n      for (let j = 0, docId; j < docs.length, docId = docs[j]; j++) {\n        if (docResults[docId] === undefined) {\n          docResults[docId] = currDocs[docId];\n        } else {\n          docResults[docId].push(...currDocs[docId]);\n        }\n      }\n    }\n    return docResults;\n  }\n}\n\n\nclass FuzzySearch {\n  constructor(query) {\n    this._fuzzy = query.value;\n    this._fuzziness = query.fuzziness !== undefined ? query.fuzziness : \"AUTO\";\n    if (this._fuzziness === \"AUTO\") {\n      if (this._fuzzy.length <= 2) {\n        this._fuzziness = 0;\n      } else if (this._fuzzy.length <= 5) {\n        this._fuzziness = 1;\n      } else {\n        this._fuzziness = 2;\n      }\n    }\n    this._prefixLength = query.prefix_length !== undefined ? query.prefix_length : 2;\n  }\n\n  /**\n   * Copyright Kigiri: https://github.com/kigiri\n   *           Milot Mirdita: https://github.com/milot-mirdita\n   *           Toni Neubert:  https://github.com/Viatorus/\n   */\n  levenshtein_distance(a, b) {\n    if (a.length === 0) return b.length;\n    if (b.length === 0) return a.length;\n    let tmp;\n    let i;\n    let j;\n    let prev;\n    let val;\n    // swap to save some memory O(min(a,b)) instead of O(a)\n    if (a.length > b.length) {\n      tmp = a;\n      a = b;\n      b = tmp;\n    }\n\n    const row = Array(a.length + 1);\n    // init the row\n    for (i = 0; i <= a.length; i++) {\n      row[i] = i;\n    }\n\n    // fill in the rest\n    for (i = 1; i <= b.length; i++) {\n      prev = i;\n      for (j = 1; j <= a.length; j++) {\n        if (b[i - 1] === a[j - 1]) {\t// match\n          val = row[j - 1];\n        } else {\n          val = Math.min(row[j - 1] + 1, // substitution\n            Math.min(prev + 1,         // insertion\n              row[j] + 1));          // deletion\n\n          // transposition.\n          if (i > 1 && j > 1 && b[i - 2] === a[j - 1] && a[j - 2] === b[i - 1]) {\n            val = Math.min(val, row[j - 1] - (a[j - 1] === b[i - 1] ? 1 : 0));\n          }\n        }\n        row[j - 1] = prev;\n        prev = val;\n      }\n      row[a.length] = prev;\n    }\n    return row[a.length];\n  }\n\n  /**\n   * Performs a fuzzy search for a given term.\n   * @param {string} query - a fuzzy term to match.\n   * @param {number} [maxDistance=2] - maximal edit distance between terms\n   * @returns {Array} - array with all matching term indices.\n   */\n  search(root) {\n    // Todo: Include levenshtein to reduce similar iterations.\n    // Tree tokens at same depth share same row until depth (should works if recursive).\n    // Pregenerate tree token ?\n    // var treeToken = Array(token.length + maxDistance);\n\n    let start = root;\n    let pre = this._fuzzy.slice(0, this._prefixLength);\n    let fuzzy = this._fuzzy;\n    if (this._prefixLength !== 0) {\n      start = InvertedIndex.getTermIndex(pre, start);\n      fuzzy = fuzzy.slice(this._prefixLength);\n    }\n    if (start === null) {\n      return [];\n    }\n    if (fuzzy.length === 0) {\n      // Return if prefixLength == this._fuzzy length.\n      return [{term: this._fuzziness, index: start, boost: 1}];\n    }\n\n    let similarTokens = [];\n\n    let stack = [start];\n    let treeStack = [\"\"];\n    do {\n      let root = stack.pop();\n      let treeTerms = treeStack.pop();\n\n      // Compare tokens if they are in near distance.\n      if (root.df !== undefined && Math.abs(fuzzy.length - treeTerms.length) <= this._fuzziness) {\n        const distance = this.levenshtein_distance(fuzzy, treeTerms);\n        if (distance <= this._fuzziness) {\n          let term = pre + treeTerms;\n          // Calculate boost.\n          let boost = 1 - distance / Math.min(term.length, this._fuzzy.length);\n          similarTokens.push({term, index: root, boost});\n        }\n      }\n\n      // Iterate over all subtrees.\n      // If token from tree is not longer than maximal distance.\n      if (treeTerms.length - fuzzy.length <= this._fuzziness) {\n        // Iterate over all subtrees.\n        let keys = Object.keys(root);\n        for (let i = 0; i < keys.length; i++) {\n          if (keys[i].length === 1) {\n            stack.push(root[keys[i]]);\n            treeStack.push(treeTerms + keys[i]);\n          }\n        }\n      }\n    } while (stack.length !== 0);\n\n    return similarTokens;\n  }\n}\n\nclass WildcardSearch {\n\n  constructor(query) {\n    this._wildcard = query.value;\n    this._result = [];\n  }\n\n  /**\n   * Performs a wild card search for a given query term.\n   * @param {string} query - a wild card query to match.\n   * @returns {Array} - array with all matching term indices.\n   */\n  search(root) {\n    // Todo: Need an implementation for star operator in the middle.\n    this._result = [];\n    this._recursive(root);\n    return this._result;\n  }\n\n  /**\n   *\n   * @param root\n   * @param idx\n   * @param term\n   * @param escaped\n   * @private\n   */\n  _recursive(root, idx = 0, term = \"\", escaped = false) {\n    if (root === null) {\n      return;\n    }\n\n    if (idx === this._wildcard.length) {\n      if (root.df !== undefined) {\n        this._result.push({index: root, term});\n      }\n      return;\n    }\n\n    if (!escaped && this._wildcard[idx] === \"\\\\\") {\n      this._recursive(root, idx + 1, term, true);\n    } else if (!escaped && this._wildcard[idx] === \"?\") {\n      let others = InvertedIndex.getNextTermIndex(root);\n      for (let i = 0; i < others.length; i++) {\n        this._recursive(others[i].index, idx + 1, term + others[i].term);\n      }\n    } else if (!escaped && this._wildcard[idx] === \"*\") {\n      // Check if asterisk is last wildcard character\n      if (idx + 1 === this._wildcard.length) {\n        let all = InvertedIndex.extendTermIndex(root);\n        for (let i = 0; i < all.length; i++) {\n          this._recursive(all[i].index, idx + 1, term + all[i].term);\n        }\n        return;\n      }\n      // Iterate over the whole tree.\n      this._recursive(root, idx + 1, term);\n      let roots = [{index: root, term: \"\"}];\n      do {\n        root = roots.pop();\n        let others = InvertedIndex.getNextTermIndex(root.index);\n        for (let i = 0; i < others.length; i++) {\n          this._recursive(others[i].index, idx + 1, term + root.term + others[i].term);\n          roots.push({index: others[i].index, term: root.term + others[i].term});\n        }\n      } while (roots.length !== 0);\n    } else {\n      this._recursive(InvertedIndex.getTermIndex(this._wildcard[idx], root), idx + 1, term + this._wildcard[idx]);\n    }\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./packages/full-text-search/src/index_searcher.js\n// module id = 4\n// module chunks = 0","export class Scorer {\n  constructor(invIdxs) {\n    this._invIdxs = invIdxs;\n    this._cache = {};\n  }\n\n  setDirty() {\n    this._cache = {};\n  }\n\n  prepare(fieldName, boost, termIdx, doScoring, docResults = {}, term = null) {\n    if (termIdx === null || termIdx.dc === undefined) {\n      return null;\n    }\n\n    let idf = this._idf(fieldName, termIdx.df);\n    let docIds = Object.keys(termIdx.dc);\n    for (let j = 0; j < docIds.length; j++) {\n      let docId = docIds[j];\n      if (docResults[docId] === undefined) {\n        docResults[docId] = [];\n      }\n\n      if (doScoring) {\n        let tf = termIdx.dc[docId];\n        docResults[docId].push({\n          type: \"BM25\",\n          tf,\n          idf,\n          boost,\n          fieldName,\n          term\n        });\n      } else {\n        docResults[docId] = [{\n          type: \"constant\", value: 1, boost, fieldName\n        }];\n      }\n    }\n\n    return docResults;\n  }\n\n  scoreConstant(boost, docId, docResults = {}) {\n    if (docResults[docId] === undefined) {\n      docResults[docId] = [];\n    }\n    docResults[docId].push({type: \"constant\", value: 1, boost});\n    return docResults;\n  }\n\n  finalScore(query, docResults = {}) {\n    let result = {};\n    let k1 = query.scoring.k1;\n    let b = query.scoring.b;\n\n    let docs = Object.keys(docResults);\n    for (let i = 0, docId; i < docs.length, docId = docs[i]; i++) {\n      let docScore = 0;\n      for (let j = 0; j < docResults[docId].length; j++) {\n        let docResult = docResults[docId][j];\n\n        let res = 0;\n        switch (docResult.type) {\n          case \"BM25\": {\n            let tf = docResult.tf;\n            let fieldLength = Scorer._calculateFieldLength(this._invIdxs[docResult.fieldName].documentStore[docId]\n              .fieldLength);\n            let avgFieldLength = this._avgFieldLength(docResult.fieldName);\n            // tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from\n            let tfNorm = (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (fieldLength / avgFieldLength)));\n            res = docResult.idf * tfNorm * docResult.boost;\n            // console.log(\n            // \tdocId + \":\" + docResult.fieldName + \":\" + docResult.term + \" = \" + res,\n            // \t\"\\n\\ttype: BM25\",\n            // \t\"\\n\\tboost: \" + docResult.boost,\n            // \t\"\\n\\tidf : \" + docResult.idf,\n            // \t\"\\n\\ttfNorm : \" + tfNorm,\n            // \t\"\\n\\ttf : \" + tf,\n            // \t\"\\n\\tavg : \" + avgFieldLength,\n            // \t\"\\n\\tfl : \" + fieldLength);\n            break;\n          }\n          case \"constant\":\n            res = docResult.value * docResult.boost;\n            /*console.log(\n\t\t\t\t\t\t \"Constant: \" + res,\n\t\t\t\t\t\t \"\\n\\tboost: \" + docResult.boost,\n\t\t\t\t\t\t \"\\n\\tvalue : \" + docResult.value);*/\n            break;\n        }\n        docScore += res;\n      }\n      //console.log(docId, \" === \", docScore);\n      result[docId] = docScore;\n    }\n    return result;\n  }\n\n  static _calculateFieldLength(fieldLength) {\n    // Lucene uses a SmallFloat (size of 1 byte) to store the field length in scoring.\n    // This is useless in javascript, because every number is represented as a double (8 byte).\n    // To align the scoring result with lucene, this calculation is still needed.\n    // Lucene also includes the field boost, but field boost is deprecated and not supported by Loki.\n\n    // Find closest value in array.\n    const lockUp = [1, 1.30612242, 1.77777779, 2.55999994, 4, 5.22448969, 7.11111116, 10.2399998, 16, 20.8979588,\n      28.4444447, 40.9599991, 64, 83.591835, 113.777779, 163.839996, 256, 334.36734, 455.111115, 655.359985, 1024,\n      1337.46936, 1820.44446, 2621.43994, 4096, 5349.87744, 7281.77783, 10485.7598, 16384, 21399.5098, 29127.1113,\n      41943.0391, 65536, 85598.0391, 116508.445, 167772.156, 262144, 342392.156, 466033.781, 671088.625, 1048576,\n      1369568.62, 1864135.12, 2684354.5, 4194304, 5478274.5, 7456540.5, 10737418, 16777216, 21913098, 29826162,\n      42949672, 67108864, 87652392, 119304648, 171798688, 268435456, 350609568, 477218592, 687194752];\n\n    for (let i = 0; i < lockUp.length; i++) {\n      if (lockUp[i] >= fieldLength) {\n        return lockUp[i];\n      }\n    }\n    throw RangeError(\"Unsupported field length.\");\n  }\n\n  _getCache(fieldName) {\n    if (this._cache[fieldName] === undefined) {\n      let avgFieldLength = this._invIdxs[fieldName].totalFieldLength / this._invIdxs[fieldName].documentCount;\n      this._cache[fieldName] = {idfs: {}, avgFieldLength};\n    }\n    return this._cache[fieldName];\n  }\n\n  /**\n\t * Returns the idf by either calculate it or use a cached one.\n\t * @param {string} fieldName - the name of the field\n\t * @param {number} docFreq - the doc frequency of the term\n\t * @returns {number} the idf\n\t * @private\n\t */\n  _idf(fieldName, docFreq) {\n    let cache = this._getCache(fieldName);\n    if (cache.idfs[docFreq] !== undefined) {\n      return cache.idfs[docFreq];\n    }\n    return cache.idfs[docFreq] = Math.log(1 + (this._invIdxs[fieldName].documentCount - docFreq + 0.5) / (docFreq + 0.5));\n  }\n\n  _avgFieldLength(fieldName) {\n    return this._getCache(fieldName).avgFieldLength;\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./packages/full-text-search/src/scorer.js\n// module id = 5\n// module chunks = 0","/**\n * Query builder\n */\n//import * as Utils from './utils.js';\n\n/**\n * The base query class to enable boost to a query type.\n */\nexport class BaseQuery {\n  protected _data: any;\n\n  /**\n   * @param {string} type - the type name of the query\n   * @param data\n   */\n  constructor(type: string, data = {}) {\n    this._data = data;\n    this._data.type = type;\n  }\n\n  /**\n   * Boosts the query result.\n   *\n   * See also [Lucene#BoostQuery]{@link https://lucene.apache.org/core/6_4_0/core/org/apache/lucene/search/BoostQuery.html}\n   * and [Elasticsearch#boost]{@link https://www.elastic.co/guide/en/elasticsearch/reference/5.2/mapping-boost.html}.\n   *\n   * @param {number} value - the positive boost\n   * @return {BaseQuery} object itself for cascading\n   */\n  boost(value: number) {\n    if (value < 0) {\n      throw TypeError(\"Boost must be a positive number.\");\n    }\n    this._data.boost = value;\n    return this;\n  }\n\n  /**\n   * Build the final query.\n   * @return {Object} - the final query\n   */\n  build() {\n    return this._data;\n  }\n}\n\n/**\n * A query which finds documents where a document field contains a term.\n *\n * See also [Lucene#TermQuery]{@link https://lucene.apache.org/core/6_4_0/core/org/apache/lucene/search/TermQuery.html}\n * and [Elasticsearch#TermQuery]{@link https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-term-query.html}.\n *\n * @example\n * new QueryBuilder()\n *   .term(\"name\", \"infinity\"])\n * .build();\n * // The resulting documents:\n * // contains the term infinity\n *\n * @extends BaseQuery\n */\nexport class TermQuery extends BaseQuery {\n  /**\n   * @param {string} field - the field name of the document\n   * @param {string} term - the term\n   * @param data\n   */\n  constructor(field: string, term: string, data: any = {}) {\n    super(\"term\", data);\n    this._data.field = field;\n    this._data.value = term;\n  }\n}\n\n/**\n * A query which finds documents where a document field contains any of the terms.\n *\n * See also [Lucene#TermRangeQuery]{@link https://lucene.apache.org/core/6_4_0/core/org/apache/lucene/search/TermRangeQuery.html}\n * and [Elasticsearch#TermsQuery]{@link https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-terms-query.html}.\n *\n * @example\n * new QueryBuilder()\n *   .terms(\"quotes\", [\"infinity\", \"atom\", \"energy\"])\n * .build();\n * // The resulting documents:\n * // contains the terms infinity, atom or energy\n *\n * @extends BaseQuery\n */\nexport class TermsQuery extends BaseQuery {\n  /**\n   * @param {string} field - the field name of the document\n   * @param {string[]} terms - the terms\n   * @param data\n   */\n  constructor(field: string, terms: Array<string>, data: any = {}) {\n    super(\"terms\", data);\n    this._data.field = field;\n    this._data.value = terms;\n  }\n}\n\n/**\n * A query which finds documents where the wildcard term can be applied at an existing document field term.\n *\n * Wildcard | Description\n * -------- | ------------\n * ? (question mark) | Skips a single character.\n *\n * To escape a wildcard character, use _\\_ (backslash), e.g. \\?.\n *\n * * To enable scoring for wildcard queries, use {@link WildcardQuery#enableScoring}.\n *\n * See also [Lucene#WildcardQuery]{@link https://lucene.apache.org/core/6_4_0/core/org/apache/lucene/search/WildcardQuery.html}\n * and [Elasticsearch#WildcardQuery]{@link https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-wildcard-query.html}.\n *\n * _TODO: Implement wildcard * (asterisk) to skip zero or more characters._\n * @todo Implement wildcard * (asterisk) to skip zero or more characters.\n *\n * @example\n * new QueryBuilder()\n *   .wildcard(\"question\", \"e?nste?n\\?\")\n * .build();\n * // The resulting documents:\n * // contains the wildcard surname e?nste?n\\? (like Einstein? or Eynsteyn? but not Einsteine or Ensten?)\n *\n * @extends BaseQuery\n */\nexport class WildcardQuery extends BaseQuery {\n  /**\n   * @param {string} field - the field name of the document\n   * @param {string} wildcard - the wildcard term\n   * @param data\n   */\n  constructor(field: string, wildcard: string, data: any = {}) {\n    super(\"wildcard\", data);\n    this._data.field = field;\n    this._data.value = wildcard;\n  }\n\n  /**\n   * This flag enables scoring for wildcard results, similar to {@link TermQuery}.\n   * @param {boolean} enable - flag to enable or disable scoring\n   * @return {WildcardQuery}\n   */\n  enableScoring(enable: boolean) {\n    this._data.enable_scoring = enable;\n    return this;\n  }\n}\n\n/**\n * A query which finds documents where the fuzzy term can be transformed into an existing document field term within a\n * given edit distance\n * ([DamerauLevenshtein distance]{@link https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance}).\n *\n * The edit distance is the minimum number of an insertion, deletion or substitution of a single character\n * or a transposition of two adjacent characters.\n *\n * * To set the maximal allowed edit distance, use {@link FuzzyQuery#fuzziness} (default is AUTO).\n * * To set the initial word length, which should ignored for fuzziness, use {@link FuzzyQuery#prefixLength}.\n *\n * See also [Lucene#FuzzyQuery]{@link https://lucene.apache.org/core/6_4_0/core/org/apache/lucene/search/FuzzyQuery.html}\n * and [Elasticsearch#FuzzyQuery]{@link https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-fuzzy-query.html}.\n *\n * @example\n * new QueryBuilder()\n *   .fuzzy(\"surname\", \"einsten\")\n *     .fuzziness(3)\n *     .prefixLength(3)\n * .build();\n * // The resulting documents:\n * // contains the fuzzy surname einstn (like Einstein or Einst but not Eisstein or Insten)\n *\n * @extends BaseQuery\n */\nexport class FuzzyQuery extends BaseQuery {\n  /**\n   * @param {string} field - the field name of the document\n   * @param {string} fuzzy - the fuzzy term\n   * @param data\n   */\n  constructor(field: string, fuzzy: string, data: any = {}) {\n    super(\"fuzzy\", data);\n    this._data.field = field;\n    this._data.value = fuzzy;\n  }\n\n  /**\n   * Sets the maximal allowed fuzziness.\n   * @param {number|string} fuzziness - the edit distance as number or AUTO\n   *\n   * AUTO generates an edit distance based on the length of the term:\n   * * 0..2 -> must match exactly\n   * * 3..5 -> one edit allowed\n   * * >5 two edits allowed\n   *\n   * @return {FuzzyQuery} - object itself for cascading\n   */\n  fuzziness(fuzziness: number | string) {\n    if (fuzziness !== \"AUTO\" && fuzziness < 0) {\n      throw TypeError(\"Fuzziness must be a positive number or AUTO.\");\n    }\n    this._data.fuzziness = fuzziness;\n    return this;\n  }\n\n  /**\n   * Sets the initial word length.\n   * @param {number} prefixLength - the positive prefix length\n   * @return {FuzzyQuery}  object itself for cascading\n   */\n  prefixLength(prefixLength: number) {\n    if (prefixLength < 0) {\n      throw TypeError(\"Prefix length must be a positive number.\");\n    }\n    this._data.prefix_length = prefixLength;\n    return this;\n  }\n}\n\n/**\n * A query which matches documents containing the prefix of a term inside a field.\n *\n * * To enable scoring for wildcard queries, use {@link WildcardQuery#enableScoring}.\n *\n * See also [Lucene#PrefixQuery]{@link https://lucene.apache.org/core/6_4_0/core/org/apache/lucene/search/PrefixQuery.html}\n * and [Elasticsearch#MatchQuery]{@link https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-prefix-query.html}\n *\n * @example\n * new QueryBuilder()\n *   .prefix(\"surname\", \"alb\")\n * .build()\n * // The resulting documents:\n * // contains the term prefix alb as surname\n *\n * @extends BaseQuery\n */\nexport class PrefixQuery extends BaseQuery {\n  /**\n   * @param {string} field - the field name of the document\n   * @param {string} prefix - the prefix of a term\n   * @param data\n   */\n  constructor(field: string, prefix: string, data: any = {}) {\n    super(\"prefix\", data);\n    this._data.field = field;\n    this._data.value = prefix;\n  }\n\n  /**\n   * This flag enables scoring for wildcard results, similar to {@link TermQuery}.\n   * @param {boolean} enable - flag to enable or disable scoring\n   * @return {PrefixQuery}\n   */\n  enableScoring(enable: boolean) {\n    this._data.enable_scoring = enable;\n    return this;\n  }\n}\n\n/**\n * A query which matches all documents with a given field.\n *\n * See also [Elasticsearch#ExistsQuery]{@link https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-exists-query.html}.\n *\n * @example\n * new QueryBuilder()\n *   .exists(\"name\")\n * .build()\n * // The resulting documents:\n * // has the field \"name\"\n *\n * @extends BaseQuery\n */\nexport class ExistsQuery extends BaseQuery {\n  /**\n   * @param {string} field - the field name of the document\n   * @param data\n   */\n  constructor(field: string, data: any = {}) {\n    super(\"exists\", data);\n    this._data.field = field;\n  }\n}\n\n/**\n * A query which tokenizes the given query text, performs a query foreach token and combines the results using a boolean\n * operator.\n *\n * Operator      | Description\n * ------------- | -------------\n * or (default) | Finds documents which matches some tokens. The minimum amount of matches can be controlled with [minimumShouldMatch]{@link MatchQuery#minimumShouldMatch} (default is 1).\n * and | Finds documents which matches all tokens.\n *\n * To enable a [fuzzy query]{@link FuzzyQuery} for the tokens, use {@link MatchQuery#fuzziness} and {@link MatchQuery#prefixLength}.\n *\n * See also [Lucene#?]{@link ?}\n * and [Elasticsearch#MatchQuery]{@link https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query.html}.\n *\n * @example\n * new QueryBuilder()\n *   .match(\"name\", \"albrt einsten\")\n *     .boost(2.5)\n *     .operator(\"and\")\n *     .fuzziness(2)\n *     .prefixLength(3)\n * .build();\n * // The resulting documents:\n * // contains the fuzzy name albrt einsten (like Albert Einstein) with a boost of 2.5\n *\n * @extends BaseQuery\n */\nexport class MatchQuery extends BaseQuery {\n  /**\n   * @param {string} field - the field name of the document\n   * @param {string} query - the query text\n   * @param data\n   */\n  constructor(field: string, query: string, data: any = {}) {\n    super(\"match\", data);\n    this._data.field = field;\n    this._data.value = query;\n  }\n\n  /**\n   * Controls the amount of minimum matching sub queries before a document will be considered.\n   * @param {number} minShouldMatch - number of minimum matching sub queries\n   *   minShouldMatch >= 1: Indicates a fixed value regardless of the number of sub queries.\n   *   minShouldMatch <= -1: Indicates that the number of sub queries, minus this number should be mandatory.\n   *   minShouldMatch < 0: Indicates that this percent of the total number of sub queries can be missing.\n   *     The number computed from the percentage is rounded down, before being subtracted from the total to determine\n   *     the minimum.\n   *   minShouldMatch < 1: Indicates that this percent of the total number of sub queries are necessary.\n   *     The number computed from the percentage is rounded down and used as the minimum.\n   * @return {MatchQuery} object itself for cascading\n   */\n  minimumShouldMatch(minShouldMatch: number) {\n    if (this._data.operator !== undefined && this._data.operator === \"and\") {\n      throw SyntaxError(\"Match query with \\\"and\\\" operator does not support minimum should match.\");\n    }\n    this._data.minimum_should_match = minShouldMatch;\n    return this;\n  }\n\n  /**\n   * Sets the boolean operator.\n   * @param {string} op - the operator (\"or\" || \"and\")\n   * @return {MatchQuery} object itself for cascading\n   */\n  operator(op: string) {\n    if (op !== \"and\" && op !== \"or\") {\n      throw SyntaxError(\"Unknown operator.\");\n    }\n    this._data.operator = op;\n    if (this._data.minimum_should_match !== undefined && this._data.operator === \"and\") {\n      throw SyntaxError(\"Match query with \\\"and\\\" operator does not support minimum should match.\");\n    }\n    return this;\n  }\n\n  /**\n   * Sets the maximal allowed fuzziness.\n   * @param {number|string} fuzziness - the edit distance as number or AUTO\n   *\n   * AUTO generates an edit distance based on the length of the term:\n   * * 0..2 -> must match exactly\n   * * 3..5 -> one edit allowed\n   * * >5 two edits allowed\n   *\n   * @return {MatchQuery} - object itself for cascading\n   */\n  fuzziness(fuzziness: number | string) {\n    if (fuzziness !== \"AUTO\" && fuzziness < 0) {\n      throw TypeError(\"Fuzziness must be a positive number or AUTO.\");\n    }\n    this._data.fuzziness = fuzziness;\n    return this;\n  }\n\n  /**\n   * Sets the starting word length which should not be considered for fuzziness.\n   * @param {number} prefixLength - the positive prefix length\n   * @return {MatchQuery} - object itself for cascading\n   */\n  prefixLength(prefixLength: number) {\n    if (prefixLength < 0) {\n      throw TypeError(\"Prefix length must be a positive number.\");\n    }\n    this._data.prefix_length = prefixLength;\n    return this;\n  }\n}\n\n/**\n * A query that matches all documents and giving them a constant score equal to the query boost.\n *\n * Typically used inside a must clause of a {@link BoolQuery} to subsequently reject non matching documents with the not\n * clause.\n *\n * See also [Lucene#MatchAllDocsQuery]{@link https://lucene.apache.org/core/6_4_0/core/org/apache/lucene/search/MatchAllDocsQuery.html}\n * and [Elasticsearch#MatchAllQuery]{@link https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-all-query.html}.\n *\n * @example\n * new QueryBuilder()\n *   .matchAll()\n *     .boost(2.5)\n * .build()\n * // The resulting documents:\n * // all documents and giving a score of 2.5\n *\n * @extends BaseQuery\n */\nexport class MatchAllQuery extends BaseQuery {\n  constructor(data = {}) {\n    super(\"match_all\", data);\n  }\n}\n\n/**\n * A query which holds all sub queries like an array.\n * @private\n */\nclass ArrayQuery extends BaseQuery {\n  private _callbackName: any;\n  private _prepare: any;\n\n  constructor(callbackName: string, callback: any, data: any = {}) {\n    super(\"array\", data);\n    this._data.values = [];\n    this._callbackName = callbackName;\n    this[callbackName] = callback;\n\n    this._prepare = (queryType: any, ...args: any[]) => {\n      let data = {};\n      let query = new queryType(...args, data);\n      this._data.values.push(data);\n      query.bool = this.bool;\n      query.constantScore = this.constantScore;\n      query.term = this.term;\n      query.terms = this.terms;\n      query.wildcard = this.wildcard;\n      query.fuzzy = this.fuzzy;\n      query.match = this.match;\n      query.matchAll = this.matchAll;\n      query.prefix = this.prefix;\n      query.exists = this.exists;\n      query._prepare = this._prepare;\n      query[this._callbackName] = this[this._callbackName];\n      return query;\n    };\n  }\n\n  bool() {\n    return this._prepare(BoolQuery);\n  }\n\n  constantScore() {\n    return this._prepare(ConstantScoreQuery);\n  }\n\n  term(field: string, term: string) {\n    return this._prepare(TermQuery, field, term);\n  }\n\n  terms(field: string, terms: Array<string>) {\n    return this._prepare(TermsQuery, field, terms);\n  }\n\n  wildcard(field: string, wildcard: string) {\n    return this._prepare(WildcardQuery, field, wildcard);\n  }\n\n  fuzzy(field: string, fuzzy: string) {\n    return this._prepare(FuzzyQuery, field, fuzzy);\n  }\n\n  match(field: string, query: string) {\n    return this._prepare(MatchQuery, field, query);\n  }\n\n  matchAll() {\n    return this._prepare(MatchAllQuery);\n  }\n\n  prefix(field: string, prefix: string) {\n    return this._prepare(PrefixQuery, field, prefix);\n  }\n\n  exists(field: string) {\n    return this._prepare(ExistsQuery, field);\n  }\n}\n\n/**\n * A query that wraps sub queries and returns a constant score equal to the query boost for every document in the filter.\n *\n * See also [Lucene#BooleanQuery]{@link https://lucene.apache.org/core/6_4_0/core/org/apache/lucene/search/ConstantScoreQuery.html}\n * and [Elasticsearch#ConstantScoreQuery]{@link https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-constant-score-query.html}.\n *\n * @example\n * new QueryBuilder()\n *   .constantScore()\n *     .boost(1.5)\n *     .beginFilter()\n *       .term(\"first_name\", \"albert\")\n *       .term(\"surname\", \"einstein\")\n *     .endFilter()\n * .build()\n * // The resulting documents:\n * // * contains albert as first name, einstein as surname and the document score is 42.\n *\n * @extends BaseQuery\n */\nexport class ConstantScoreQuery extends BaseQuery {\n  constructor(data: any = {}) {\n    super(\"constant_score\", data);\n  }\n\n  /**\n   * Starts an array of queries. Use endFilter() to finish the array.\n   * @return {ArrayQuery} array query for holding sub queries\n   */\n  beginFilter() {\n    this._data.filter = {};\n    return new ArrayQuery(\"endFilter\", () => {\n      return this;\n    }, this._data.filter);\n  }\n}\n\n/**\n * A query that matches documents matching boolean combinations of sub queries.\n *\n * This query consists of one or more boolean clauses with different behavior but interrelated to each other.\n *\n * Occur         | Description\n * ------------- | -------------\n * must  | Finds documents which matches all sub queries.\n * filter  | Finds documents which matches all sub queries but these documents do not contribute to the score.\n * should  | Finds documents which matches some sub queries. The minimum amount of matches can be controlled with [minimumShouldMatch]{@link BoolQuery#minimumShouldMatch} (default is 1).\n * not  | Documents which match any sub query will be ignored.\n *\n * A sub query can be any other query type and also the bool query itself.\n *\n * See also [Lucene#BooleanQuery]{@link https://lucene.apache.org/core/6_4_0/core/org/apache/lucene/search/BooleanQuery.html}\n * and [Elasticsearch#BoolQuery]{@link https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html}.\n *\n * @example\n * new QueryBuilder()\n *   .bool()\n *     .beginMust().boost(2)\n *       .term(\"first_name\", \"albert\")\n *     .endMust()\n *     .beginFilter()\n *       .term(\"birthplace\", \"ulm\")\n *     .endFilter()\n *     .beginShould().minimumShouldMatch(2)\n *       .fuzzy(\"surname\", \"einstin\")\n *       .wildcard(\"name\", \"geni?s\")\n *       .term(\"quotes\", \"infinity\")\n *     .endShould()\n *     .beginNot()\n *       .terms(\"research_field\", [\"biology\", \"geography\"])\n *     .endNot()\n * .build();\n * // The resulting documents:\n * // contains the name albert (must: contribute to the score with a boost of 2)\n * // contains the birthplace ulm (filter: not contribute to the score)\n * // contains a minimum of two matches from the fuzzy, wildcard and/or term query (should: contribute to the score)\n * // do not contains biology or geography as research field (not: not contribute to the score)\n *\n * @extends BaseQuery\n */\nexport class BoolQuery extends BaseQuery {\n  constructor(data: any = {}) {\n    super(\"bool\", data);\n  }\n\n  /**\n   * Starts an array of queries for must clause. Use endMust() to finish the array.\n   * @return {ArrayQuery} array query for holding sub queries\n   */\n  beginMust() {\n    this._data.must = {};\n    return new ArrayQuery(\"endMust\", () => {\n      return this;\n    }, this._data.must);\n  }\n\n  /**\n   * Starts an array of queries for filter clause. Use endFilter() to finish the array.\n   * @return {ArrayQuery} array query for holding sub queries\n   */\n  beginFilter() {\n    this._data.filter = {};\n    return new ArrayQuery(\"endFilter\", () => {\n      return this;\n    }, this._data.filter);\n  }\n\n  /**\n   * Starts an array of queries for should clause. Use endShould() to finish the array.\n   * @return {ArrayQuery} array query for holding sub queries\n   */\n  beginShould() {\n    this._data.should = {};\n    return new ArrayQuery(\"endShould\", () => {\n      return this;\n    }, this._data.should);\n  }\n\n  /**\n   * Starts an array of queries for not clause. Use endNot() to finish the array.\n   * @return {ArrayQuery} array query for holding sub queries\n   */\n  beginNot() {\n    this._data.not = {};\n    return new ArrayQuery(\"endNot\", () => {\n      return this;\n    }, this._data.not);\n  }\n\n  /**\n   * Controls the amount of minimum matching sub queries before a document will be considered.\n   * @param {number} minShouldMatch - number of minimum matching sub queries\n   *   minShouldMatch >= 1: Indicates a fixed value regardless of the number of sub queries.\n   *   minShouldMatch <= -1: Indicates that the number of sub queries, minus this number should be mandatory.\n   *   minShouldMatch < 0: Indicates that this percent of the total number of sub queries can be missing.\n   *     The number computed from the percentage is rounded down, before being subtracted from the total to determine\n   *     the minimum.\n   *   minShouldMatch < 1: Indicates that this percent of the total number of sub queries are necessary.\n   *     The number computed from the percentage is rounded down and used as the minimum.\n   * @return {BoolQuery} object itself for cascading\n   */\n  minimumShouldMatch(minShouldMatch: number) {\n    this._data.minimum_should_match = minShouldMatch;\n    return this;\n  }\n}\n\n/**\n * This query builder is the root of each query search.\n * The query contains a sub query and parameters for setup scoring and search options.\n *\n * Possible sub query types are:\n * {@link TermQuery}, {@link TermsQuery}, {@link FuzzyQuery}, {@link WildcardQuery},\n * {@link MatchQuery}, {@link MatchAllQuery}, {@link PrefixQuery},  {@link BoolQuery},\n * {@link ConstantScoreQuery}, {@link ExistsQuery}\n *\n * @example\n * new QueryBuilder()\n *   .finalScoring(true)\n *   .useBM25(1.5, 0.5)\n *   .term(\"first_name\", \"albert\")\n * .build();\n * // The resulting documents:\n * // contains the first name albert\n * // are scored and ranked using BM25 with k1=1.5 and b=0.5\n */\nexport class QueryBuilder {\n  private _data: any;\n  private _child: any;\n\n  constructor() {\n    this._data = {query: {}};\n    this.useBM25();\n  }\n\n  /**\n   * The query performs a final scoring over all scored sub queries and rank documents by there relevant.\n   * @param {boolean} enable - flag to enable or disable final scoring\n   * @return {QueryBuilder}\n   */\n  enableFinalScoring(enable: boolean) {\n    this._data.final_scoring = enable;\n    return this;\n  }\n\n  /**\n   * Use [Okapi BM25]{@link https://en.wikipedia.org/wiki/Okapi_BM25} as scoring model (default).\n   *\n   * See also [Lucene#MatchAllDocsQuery]{@link https://lucene.apache.org/core/6_4_0/core/org/apache/lucene/search/similarities/BM25Similarity.html}\n   * and [Elasticsearch#BM25]{@link https://www.elastic.co/guide/en/elasticsearch/guide/current/pluggable-similarites.html#bm25}.\n   *\n   * @param {number} [k1=1.2] - controls how quickly an increase in term frequency results in term-frequency saturation.\n   *                            Lower values result in quicker saturation, and higher values in slower saturation.\n   * @param {number} [b=0.75] - controls how much effect field-length normalization should have.\n   *                            A value of 0.0 disables normalization completely, and a value of 1.0 normalizes fully.\n   * @return {QueryBuilder}\n   */\n  useBM25(k1: number = 1.2, b: number = 0.75) {\n    if (k1 < 0) {\n      throw TypeError(\"BM25s k1 must be a positive number.\");\n    }\n    if (b < 0 || b > 1) {\n      throw TypeError(\"BM25s b must be a number between 0 and 1 inclusive.\");\n    }\n\n    this._data.scoring = {\n      type: \"BM25\",\n      k1,\n      b\n    };\n    return this;\n  }\n\n  bool() {\n    return this._prepare(BoolQuery);\n  }\n\n  constantScore() {\n    return this._prepare(ConstantScoreQuery);\n  }\n\n  term(field: string, term: string) {\n    return this._prepare(TermQuery, field, term);\n  }\n\n  terms(field: string, terms: Array<string>) {\n    return this._prepare(TermsQuery, field, terms);\n  }\n\n  wildcard(field: string, wildcard: string) {\n    return this._prepare(WildcardQuery, field, wildcard);\n  }\n\n  fuzzy(field: string, fuzzy: string) {\n    return this._prepare(FuzzyQuery, field, fuzzy);\n  }\n\n  match(field: string, query: string) {\n    return this._prepare(MatchQuery, field, query);\n  }\n\n  matchAll() {\n    return this._prepare(MatchAllQuery);\n  }\n\n  prefix(field: string, prefix: string) {\n    return this._prepare(PrefixQuery, field, prefix);\n  }\n\n  exists(field: string) {\n    return this._prepare(ExistsQuery, field);\n  }\n\n  _prepare(queryType: any, ...args: any[]) {\n    this._child = new queryType(...args, this._data.query);\n    this._child.build = () => {\n      return this._data;\n    };\n    return this._child;\n  }\n}\n\n\n\n// WEBPACK FOOTER //\n// ./packages/full-text-search/src/queries.ts"],"sourceRoot":""}